import re
import chromadb
from difflib import SequenceMatcher
from sentence_transformers import SentenceTransformer

CHROMA_DIR           = r"chroma_db"
COLLECTION           = "laptops"
MODEL_NAME           = "intfloat/multilingual-e5-large"
SIMILARITY_THRESHOLD = 0.78
LOOKUP_THRESHOLD     = 0.7

LOOKUP_KEYWORDS = [
    "th√¥ng tin", "tra c·ª©u", "cho t√¥i bi·∫øt", "cho m√¨nh bi·∫øt",
    "c·∫•u h√¨nh", "th√¥ng s·ªë", "specs", "chi ti·∫øt", "xem chi ti·∫øt",
    "c·∫•u h√¨nh c·ªßa", "th√¥ng s·ªë c·ªßa", "specs c·ªßa",
]

DEDICATED_KEYWORDS = [
    "gaming", "game", "ch∆°i game", "chi·∫øn game", "ƒëi·ªán t·ª≠",
    "render", "d·ª±ng phim", "edit video", "ch·ªânh phim",
    "ƒë·ªì h·ªça", "thi·∫øt k·∫ø", "3d",
    "gpu r·ªùi", "card r·ªùi",
    "rtx", "gtx", "rx 6", "rx 7", "nvidia", "radeon",
    "stream",
]

INTEGRATED_KEYWORDS = [
    "vƒÉn ph√≤ng", "office", "card t√≠ch h·ª£p", "kh√¥ng c·∫ßn gpu",
    "h·ªçc t·∫≠p", "sinh vi√™n c∆° b·∫£n", "l∆∞·ªõt web", "xem phim",
    "m·ªèng nh·∫π", "pin tr√¢u", "di chuy·ªÉn nhi·ªÅu",
]

BRAND_MAP = {
    "apple": "Apple",    "macbook": "Apple",   "mac": "Apple",
    "dell": "Dell",      "xps": "Dell",        "inspiron": "Dell",
    "hp": "HP",          "pavilion": "HP",     "envy": "HP",
    "spectre": "HP",     "omen": "HP",
    "asus": "ASUS",      "vivobook": "ASUS",   "zenbook": "ASUS",
    "rog": "ASUS",       "tuf": "ASUS",
    "lenovo": "Lenovo",  "thinkpad": "Lenovo", "ideapad": "Lenovo",
    "yoga": "Lenovo",    "legion": "Lenovo",
    "acer": "Acer",      "aspire": "Acer",     "swift": "Acer",
    "nitro": "Acer",     "predator": "Acer",
    "msi": "MSI",        "raider": "MSI",      "stealth": "MSI",
    "prestige": "MSI",   "katana": "MSI",
    "samsung": "Samsung","galaxy book": "Samsung",
    "gigabyte": "GIGABYTE", "aorus": "GIGABYTE",
}

BRAND_NAMES = [
    "macbook", "apple", "dell", "hp", "asus", "lenovo", "acer",
    "msi", "samsung", "gigabyte", "vivobook", "zenbook", "rog",
    "tuf", "thinkpad", "ideapad", "legion", "aspire", "swift",
    "nitro", "predator", "pavilion", "envy", "spectre", "omen",
    "xps", "inspiron", "raider", "stealth", "katana", "aorus",
]

BRAND_ONLY = [
    "apple", "dell", "hp", "asus", "lenovo", "acer",
    "msi", "samsung", "gigabyte", "mac", "macbook",
]

SEARCH_INTENT_WORDS = [
    "t√¥i c·∫ßn", "t√¥i mu·ªën", "cho t√¥i", "g·ª£i √Ω", "t∆∞ v·∫•n",
    "n√™n mua", "laptop n√†o", "m√°y n√†o", "t√¨m ki·∫øm",
    "d∆∞·ªõi", "t·∫ßm", "kho·∫£ng", "gaming", "sinh vi√™n",
]


def load_retriever():
    model      = SentenceTransformer(MODEL_NAME)
    client     = chromadb.PersistentClient(path=CHROMA_DIR)
    collection = client.get_collection(COLLECTION)
    print(f"[LOAD] '{COLLECTION}' ‚Äî {collection.count()} vectors")
    return model, collection


def is_direct_name(query: str) -> bool:
    q             = query.lower().strip()
    has_brand     = any(b in q for b in BRAND_NAMES)
    is_short      = len(q.split()) <= 8
    is_not_search = not any(w in q for w in SEARCH_INTENT_WORDS)
    is_brand_only = any(q == b or q == f"laptop {b}" for b in BRAND_ONLY)
    return has_brand and is_short and is_not_search and not is_brand_only


def is_lookup(query: str) -> bool:
    return any(kw in query.lower() for kw in LOOKUP_KEYWORDS)


def parse_intent(query: str) -> dict:
    q = query.lower()
    filters = {}

    m = re.search(r"(?:d∆∞·ªõi|<|max|t·ªëi ƒëa|kh√¥ng qu√°)\s*(\d+(?:[.,]\d+)?)\s*(tr(?:i·ªáu)?|m(?:i·ªáu)?)?", q)
    if m:
        val = float(m.group(1).replace(",", "."))
        filters["max_price"] = val * 1_000_000 if val < 1000 else val

    m = re.search(r"(?:t·∫ßm|kho·∫£ng|trong t·∫ßm|t·∫ßm gi√°)\s*(\d+(?:[.,]\d+)?)\s*(tr(?:i·ªáu)?|m(?:i·ªáu)?)?", q)
    if m:
        val = float(m.group(1).replace(",", "."))
        mid = val * 1_000_000 if val < 1000 else val
        filters["min_price"] = mid * 0.90
        filters["max_price"] = mid * 1.15

    m = re.search(r"(?:tr√™n|t·ª´|t·ªëi thi·ªÉu|√≠t nh·∫•t|>=|min)\s*(\d+(?:[.,]\d+)?)\s*(tr(?:i·ªáu)?|m(?:i·ªáu)?)?", q)
    if m:
        val = float(m.group(1).replace(",", "."))
        filters["min_price"] = val * 1_000_000 if val < 1000 else val

    m = re.search(r"(\d+(?:[.,]\d+)?)\s*(?:tr(?:i·ªáu)?)?\s*[-‚Äì~ƒë·∫øn t·ªõi]+\s*(\d+(?:[.,]\d+)?)\s*(tr(?:i·ªáu)?)?", q)
    if m:
        lo = float(m.group(1).replace(",", "."))
        hi = float(m.group(2).replace(",", "."))
        if lo < 1000: lo, hi = lo * 1_000_000, hi * 1_000_000
        filters["min_price"] = lo
        filters["max_price"] = hi

    m = re.search(r"(?:ram\s*(\d+)|(\d+)\s*gb\s*ram|(?:√≠t nh·∫•t|t·ªëi thi·ªÉu|>=|min)\s*(\d+)\s*gb)", q)
    if m:
        filters["min_ram"] = float(next(v for v in m.groups() if v))

    m = re.search(r"(?:(\d+)\s*tb\s*ssd|ssd\s*(\d+)\s*tb|(\d+)\s*gb\s*ssd|ssd\s*(\d+)\s*gb)", q)
    if m:
        val = float(next(v for v in m.groups() if v))
        filters["min_storage"] = val * 1024 if "tb" in q and val < 10 else val

    if any(kw in q for kw in DEDICATED_KEYWORDS):
        filters["gpu_type"] = "dedicated"
    elif any(kw in q for kw in INTEGRATED_KEYWORDS):
        filters["gpu_type"] = "integrated"

    for keyword, brand_val in BRAND_MAP.items():
        if keyword in q:
            filters["brand"] = brand_val
            break

    return filters



def build_where_filter(
    max_price  : float = None,
    min_price  : float = None,
    min_ram    : float = None,
    min_storage: float = None,
    gpu_type   : str   = None,
    brand      : str   = None,
) -> dict | None:
    filters = []
    if max_price  : filters.append({"price"   : {"$lte": max_price}})
    if min_price  : filters.append({"price"   : {"$gte": min_price}})
    if min_ram    : filters.append({"ram"     : {"$gte": min_ram}})
    if min_storage: filters.append({"storage" : {"$gte": min_storage}})
    if gpu_type   : filters.append({"gpu_type": {"$eq" : gpu_type}})
    if brand      : filters.append({"brand"   : {"$eq" : brand}})

    if   len(filters) == 0: return None
    elif len(filters) == 1: return filters[0]
    else                  : return {"$and": filters}


def search(
    query      : str,
    model      : SentenceTransformer,
    collection : chromadb.Collection,
    top_k      : int   = 6,
    max_price  : float = None,
    min_price  : float = None,
    min_ram    : float = None,
    min_storage: float = None,
    gpu_type   : str   = None,
    brand      : str   = None,
) -> tuple[list[dict], dict]:

    auto_filters  = parse_intent(query)
    manual        = {k: v for k, v in {
        "max_price": max_price, "min_price": min_price,
        "min_ram"  : min_ram,   "min_storage": min_storage,
        "gpu_type" : gpu_type,  "brand": brand,
    }.items() if v is not None}
    final_filters = {**auto_filters, **manual}

    where        = build_where_filter(**final_filters)
    query_vector = model.encode([f"query: {query}"], normalize_embeddings=True).tolist()

    results = collection.query(
        query_embeddings = query_vector,
        n_results        = top_k,
        where            = where,
        include          = ["documents", "metadatas", "distances"],
    )

    output = []
    for i in range(len(results["ids"][0])):
        similarity = round(1 - results["distances"][0][i], 3)
        if similarity < SIMILARITY_THRESHOLD:
            continue
        meta = results["metadatas"][0][i]
        output.append({
            "rank"       : i + 1,
            "name"       : meta["name"],
            "brand"      : meta["brand"],
            "cpu"        : meta["cpu"],
            "ram"        : meta["ram"],
            "gpu"        : meta["gpu"],
            "storage"    : meta["storage"],
            "screen_size": meta["screen_size"],
            "price"      : meta["price"],
            "rating"     : meta["rating"],
            "similarity" : similarity,
            "mo_ta"      : results["documents"][0][i],
        })

    return output, final_filters


def name_similarity(a: str, b: str) -> float:
    return SequenceMatcher(None, a.lower(), b.lower()).ratio()


def lookup(
    query      : str,
    model      : SentenceTransformer,
    collection : chromadb.Collection,
    top_k      : int = 6,
) -> dict | None:
    query_vector = model.encode([f"query: {query}"], normalize_embeddings=True).tolist()

    results = collection.query(
        query_embeddings = query_vector,
        n_results        = top_k,
        include          = ["documents", "metadatas", "distances"],
    )

    if not results["ids"][0]:
        return None

    candidates = []
    for i in range(len(results["ids"][0])):
        sem_score  = round(1 - results["distances"][0][i], 3)
        if sem_score < LOOKUP_THRESHOLD:
            continue
        meta        = results["metadatas"][0][i]
        name_score  = name_similarity(query, meta["name"])
        final_score = round(0.4 * sem_score + 0.6 * name_score, 4)
        candidates.append({
            "name"       : meta["name"],
            "brand"      : meta["brand"],
            "cpu"        : meta["cpu"],
            "ram"        : meta["ram"],
            "gpu"        : meta["gpu"],
            "storage"    : meta["storage"],
            "screen_size": meta["screen_size"],
            "price"      : meta["price"],
            "rating"     : meta["rating"],
            "similarity" : sem_score,
            "final_score": final_score,
            "mo_ta"      : results["documents"][0][i],
        })

    if not candidates:
        return None

    return max(candidates, key=lambda x: x["final_score"])


def print_card(r: dict):
    print(f"\n  {'‚òÖ' * int(r['rating'])}  [{r['similarity']}]  {r['name']} - {r['price']:,.0f} VNƒê")
    print(f"  {'‚îÄ' * 55}")


def print_lookup_card(r: dict):
    print("\n" + "=" * 60)
    print(f"  üìã {r['name']}  (similarity: {r['similarity']})")
    print("=" * 60)
    print(f"  H√£ng     : {r['brand']}")
    print(f"  CPU      : {r['cpu']}")
    print(f"  RAM      : {r['ram']}GB   |  Storage : {r['storage']}GB")
    print(f"  GPU      : {r['gpu']}")
    print(f"  M√†n h√¨nh : {r['screen_size']} inch")
    print(f"  Gi√°      : {r['price']:,.0f} VNƒê")
    print(f"  Rating   : {r['rating']}/5")
    print(f"\n  M√¥ t·∫£:\n  {r['mo_ta']}")
    print("=" * 60)


if __name__ == "__main__":
    model, collection = load_retriever()

    print("=" * 60)
    print("   LAPTOP ASSISTANT  |  'exit' ƒë·ªÉ tho√°t")
    print("=" * 60)

    while True:
        query = input("\nüí¨ Nh·∫≠p c√¢u h·ªèi: ").strip()
        if query.lower() == "exit":
            print("T·∫°m bi·ªát! üëã")
            break
        if not query:
            continue

        if is_direct_name(query) or is_lookup(query):
            print("\nüìã Ch·∫ø ƒë·ªô: TRA C·ª®U")
            result = lookup(query, model, collection)
            if result:
                print_lookup_card(result)
            else:
                print("  ‚ùå Kh√¥ng t√¨m th·∫•y m√°y ph√π h·ª£p ho·∫∑c c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn laptop.")

        else:
            results, used_filters = search(query, model, collection, top_k=5)
            mode = "üü† Hybrid" if used_filters else "üîµ Semantic"
            print(f"\n{mode}  |  Filters: {used_filters or 'none'}")
            print("=" * 60)

            if not results:
                print("  ‚ùå Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ ph√π h·ª£p.")
                print("  üí° Th·ª≠ h·ªèi: 'laptop gaming d∆∞·ªõi 25 tri·ªáu' ho·∫∑c 'c·∫•u h√¨nh MacBook Air M4'")
                continue

            for r in results:
                print_card(r)
