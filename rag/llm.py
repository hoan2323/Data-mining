from groq import Groq
from search import load_retriever, search, lookup, is_direct_name, is_lookup
from apikey import API_KEY


GROQ_API_KEY = API_KEY
GROQ_MODEL   = "meta-llama/llama-4-scout-17b-16e-instruct"

llm = Groq(api_key=GROQ_API_KEY)


SYSTEM_PROMPT = """B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n laptop chuy√™n nghi·ªáp t·∫°i c·ª≠a h√†ng c√¥ng ngh·ªá.

Nhi·ªám v·ª•:
- D·ª±a v√†o danh s√°ch laptop ƒë∆∞·ª£c cung c·∫•p, t∆∞ v·∫•n cho kh√°ch h√†ng m·ªôt c√°ch t·ª± nhi√™n, th√¢n thi·ªán.
- Gi·∫£i th√≠ch t·∫°i sao laptop ƒë√≥ ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa kh√°ch.
- N·∫øu c√≥ nhi·ªÅu l·ª±a ch·ªçn, so s√°nh ng·∫Øn g·ªçn v√† ƒë∆∞a ra g·ª£i √Ω t·ªët nh·∫•t.
- N·∫øu kh√¥ng t√¨m th·∫•y laptop ph√π h·ª£p, xin l·ªói v√† g·ª£i √Ω kh√°ch m√¥ t·∫£ l·∫°i nhu c·∫ßu.
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu, kh√¥ng qu√° 300 t·ª´.
- Kh√¥ng b·ªãa th√™m th√¥ng tin ngo√†i d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p.
"""


def format_search_context(results: list[dict]) -> str:
    if not results:
        return "Kh√¥ng t√¨m th·∫•y laptop ph√π h·ª£p."

    lines = []
    for r in results:
        lines.append(
            f"- {r['name']}\n"
            f"  CPU: {r['cpu']} | RAM: {r['ram']}GB | Storage: {r['storage']}GB\n"
            f"  GPU: {r['gpu']}\n"
            f"  M√†n h√¨nh: {r['screen_size']} inch | Gi√°: {r['price']:,.0f}ƒë | Rating: {r['rating']}/5\n"
            f"  M√¥ t·∫£: {r['mo_ta'][:200]}..."
        )
    return "\n".join(lines)


def format_lookup_context(result: dict) -> str:
    if not result:
        return "Kh√¥ng t√¨m th·∫•y th√¥ng tin m√°y."

    return (
        f"- {result['name']}\n"
        f"  H√£ng: {result['brand']} | CPU: {result['cpu']}\n"
        f"  RAM: {result['ram']}GB | Storage: {result['storage']}GB\n"
        f"  GPU: {result['gpu']}\n"
        f"  M√†n h√¨nh: {result['screen_size']} inch | Gi√°: {result['price']:,.0f}ƒë | Rating: {result['rating']}/5\n"
        f"  M√¥ t·∫£: {result['mo_ta']}"
    )


def ask_llm(user_query: str, context: str, history: list) -> str:
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]

    for h in history[-3:]:
        messages.append({"role": "user",      "content": h["user"]})
        messages.append({"role": "assistant", "content": h["assistant"]})

    messages.append({
        "role": "user",
        "content": (
            f"--- D·ªØ li·ªáu laptop t√¨m ƒë∆∞·ª£c ---\n{context}\n\n"
            f"--- C√¢u h·ªèi c·ªßa kh√°ch ---\n{user_query}"
        )
    })

    response = llm.chat.completions.create(
        model    = GROQ_MODEL,
        messages = messages,
    )
    return response.choices[0].message.content.strip()

if __name__ == "__main__":
    model, collection = load_retriever()
    history = []

    print("=" * 60)
    print("   ü§ñ T∆Ø V·∫§N LAPTOP AI  |  'exit' ƒë·ªÉ tho√°t")
    print("=" * 60)

    # L·ªùi ch√†o m·ªü ƒë·∫ßu
    greeting = llm.chat.completions.create(
        model    = GROQ_MODEL,
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user",   "content": "H√£y ch√†o kh√°ch h√†ng, gi·ªõi thi·ªáu b·∫£n th√¢n v√† h·ªèi kh√°ch c·∫ßn h·ªó tr·ª£ g√¨."},
        ]
    ).choices[0].message.content.strip()
    print(f"\nü§ñ {greeting}\n")

    while True:
        query = input("üí¨ B·∫°n: ").strip()
        if query.lower() == "exit":
            break
        if not query:
            continue

        if is_direct_name(query) or is_lookup(query):
            result  = lookup(query, model, collection)
            context = format_lookup_context(result)
        else:
            results, _ = search(query, model, collection, top_k=5)
            context    = format_search_context(results)

        answer = ask_llm(query, context, history)
        print(f"\nü§ñ {answer}\n")

        history.append({"user": query, "assistant": answer})
